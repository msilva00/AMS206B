\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Assignment 4},
            pdfauthor={Mary Silva},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Assignment 4}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Mary Silva}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{3/13/2019}


\begin{document}
\maketitle

\subsection{1A}\label{a}

Using \(\theta_1 = 1.5\) and \(\theta_2 = 2\) we draw a sample of size
1000 using the independence Metropolis Hastings algorithm with gamma
distribution as the proposal density.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theta_}\DecValTok{1}\NormalTok{ =}\StringTok{ }\FloatTok{1.5} \CommentTok{# true value theta1}
\NormalTok{theta_}\DecValTok{2}\NormalTok{ =}\StringTok{ }\DecValTok{2} \CommentTok{# true value theta2}
\NormalTok{mean_z1 =}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(theta_}\DecValTok{2}\OperatorTok{/}\NormalTok{theta_}\DecValTok{1}\NormalTok{)}
\NormalTok{mean_z2 =}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(theta_}\DecValTok{1}\OperatorTok{/}\NormalTok{theta_}\DecValTok{2}\NormalTok{) }\OperatorTok{+}\StringTok{ }\DecValTok{1}\OperatorTok{/}\NormalTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{theta_}\DecValTok{2}\NormalTok{)}

\CommentTok{# hyperparams}
\NormalTok{b =}\StringTok{ }\FloatTok{2.5}
\NormalTok{a =}\StringTok{ }\NormalTok{mean_z1}\OperatorTok{*}\NormalTok{b}
\CommentTok{#M-H Algorithm}
\NormalTok{MH_alg1 =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(N)\{}
\NormalTok{  MH_samples =}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\OtherTok{NA}\NormalTok{, N)}
\NormalTok{  count =}\StringTok{ }\DecValTok{0}
\NormalTok{  current_z =}\StringTok{ }\FloatTok{1.0}
  \ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{N)\{}
\NormalTok{    curr_p =}\StringTok{ }\KeywordTok{pdf_z}\NormalTok{(current_z) }
\NormalTok{    z_new =}\StringTok{ }\KeywordTok{rgamma}\NormalTok{(}\DecValTok{1}\NormalTok{, a, b)}
\NormalTok{    p_new =}\StringTok{ }\KeywordTok{pdf_z}\NormalTok{(z_new)}
    
\NormalTok{    accept =}\StringTok{ }\KeywordTok{exp}\NormalTok{(p_new }\OperatorTok{+}\StringTok{ }\KeywordTok{dgamma}\NormalTok{(current_z,a,b,}\DataTypeTok{log =}\NormalTok{ T) }\OperatorTok{-}\StringTok{ }
\StringTok{                   }\NormalTok{p_new }\OperatorTok{-}\StringTok{ }\KeywordTok{dgamma}\NormalTok{(z_new,a,b,}\DataTypeTok{log =}\NormalTok{ T))}
    \ControlFlowTok{if}\NormalTok{(}\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{<}\StringTok{ }\NormalTok{accept)\{}
\NormalTok{      current_z =}\StringTok{ }\NormalTok{z_new}
\NormalTok{      count =}\StringTok{ }\NormalTok{count }\OperatorTok{+}\StringTok{ }\DecValTok{1}
\NormalTok{    \}}
\NormalTok{    MH_samples[i] =}\StringTok{ }\NormalTok{current_z}
\NormalTok{  \}}
  \KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{MH_samples=}\NormalTok{MH_samples,}\DataTypeTok{count=}\NormalTok{count))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

After trying several hyperparameters for different Gamma distributions,
the best sample obtains a mean, \(E(Z)\), of

\begin{verbatim}
## [1] 1.763996
\end{verbatim}

\(E(1/Z)\)

\begin{verbatim}
## [1] 1.537128
\end{verbatim}

and an accuracy of

\begin{verbatim}
## [1] 0.513
\end{verbatim}

The traceplot for the samples for Metropolis-Hastings is shown below:

\includegraphics{AMS206b_H4_files/figure-latex/unnamed-chunk-5-1.pdf}

\subsection{1B}\label{b}

The density of \(W = log(Z)\) is given by
\[ f_W(w) \propto \exp\left\{- \frac{3}{2} w - \theta_1 exp\{w\} - \frac{\theta_2}{\exp(w)} \right\} \exp(w) \]

We draw a sample of size 1000 using the random-walk Metropolis algorithm
with this density.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{v =}\StringTok{ }\FloatTok{0.01}
\NormalTok{MH_RW =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(N)\{}
\NormalTok{  N =}\StringTok{ }\NormalTok{N}
\NormalTok{  MH_RW =}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\OtherTok{NA}\NormalTok{, N)}
\NormalTok{  a_count =}\StringTok{ }\DecValTok{0}
\NormalTok{  z_curr =}\StringTok{ }\FloatTok{1.0}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{N) \{}
\NormalTok{    p_curr =}\StringTok{ }\KeywordTok{pdf_z2}\NormalTok{(z_curr)}
\NormalTok{    z_new =}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\KeywordTok{log}\NormalTok{(z_curr) }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\KeywordTok{sqrt}\NormalTok{(v)))}
\NormalTok{    p_new =}\StringTok{ }\KeywordTok{pdf_z2}\NormalTok{(z_new)}
\NormalTok{    acceptance =}\StringTok{ }\KeywordTok{exp}\NormalTok{(p_new }\OperatorTok{-}\StringTok{ }\NormalTok{p_curr)}
    \ControlFlowTok{if}\NormalTok{(}\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{<}\StringTok{ }\NormalTok{acceptance)\{}
\NormalTok{      z_curr =}\StringTok{ }\NormalTok{z_new}
\NormalTok{      a_count =}\StringTok{ }\NormalTok{a_count}\OperatorTok{+}\DecValTok{1}
\NormalTok{    \}}
\NormalTok{    MH_RW[i] =}\StringTok{ }\NormalTok{z_curr}
\NormalTok{  \}}
  \KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{MH_RW=}\NormalTok{MH_RW, }\DataTypeTok{a_count=}\NormalTok{a_count))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The mean for the samples, \(E(W_{samples})\), is

\begin{verbatim}
## [1] 1.114488
\end{verbatim}

And the accuracy is

\begin{verbatim}
## [1] 0.9363
\end{verbatim}

If we use 10000 metropolis hastings random ralk samples, the traceplot
is shown below

\includegraphics{AMS206b_H4_files/figure-latex/unnamed-chunk-11-1.pdf}

\subsection{2A}\label{a-1}

\[x_i |\nu,\theta \sim Gamma(\nu,\theta)\] \[\nu \sim Gamma(a,b)\]
\[\theta \sim Gamma(\alpha,\beta)\] The joint posterior for \(\theta\)
and \(\nu\)
\[\pi(\theta,\nu,\pmb{x}) \propto  \frac{\left(\prod_{i=1}^nx_i \right)^{\nu-1}\nu^{a-1} e^{-b\nu}}{\left(\Gamma(\nu) \right)^n} \theta^{a+n\nu-1} \exp\left\{-\theta\left(\beta + \sum_{i=1}^n x_i \right) \right\}\]

The full conditionals:
\[\pi(\theta|\nu, \pmb{x}) \propto \theta^{a+n\nu-1}\exp\left\{-\theta\left(\beta + \sum_{i=1}^n x_i \right) \right\}\]

thus, \(\theta|\nu, \pmb{x} \sim Gamma(n\nu, \beta + \sum x_i)\).

\[\pi(\nu|\theta,\pmb{x}) \propto \theta^{n\nu}\frac{\left(\prod_{i=1}^nx_i \right)^{\nu-1}\nu^{a-1} e^{-b\nu}}{\left(\Gamma(\nu) \right)^n}\]

which is not a recognizable distribution. We use a Metropolis within
Gibbs algorithm to sample from the full conditionals, using a random
walk proposal on \(log(\nu)\). I tried various hyperparameters
appropriate for this data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sample =}\StringTok{ }\OtherTok{NULL}
\NormalTok{N =}\StringTok{ }\DecValTok{1000}
\NormalTok{sample}\OperatorTok{$}\NormalTok{theta =}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\OtherTok{NA}\NormalTok{,N)}
\NormalTok{sample}\OperatorTok{$}\NormalTok{nu =}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\OtherTok{NA}\NormalTok{,N)}
\NormalTok{alpha =}\StringTok{ }\DecValTok{3}
\NormalTok{beta =}\StringTok{ }\DecValTok{2}
\NormalTok{v =}\StringTok{ }\FloatTok{0.05}
\NormalTok{theta_curr =}\StringTok{ }\DecValTok{2}
\NormalTok{nu_curr =}\StringTok{ }\DecValTok{3}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{N)\{}
\NormalTok{  theta_curr =}\StringTok{ }\KeywordTok{rgamma}\NormalTok{(}\DecValTok{1}\NormalTok{, n}\OperatorTok{*}\NormalTok{nu_curr }\OperatorTok{+}\StringTok{ }\NormalTok{alpha, beta }\OperatorTok{+}\StringTok{ }\NormalTok{sum_x)}
\NormalTok{  nu_new =}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\KeywordTok{log}\NormalTok{(nu_curr) }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\KeywordTok{sqrt}\NormalTok{(v)))}
\NormalTok{  pnu_curr =}\StringTok{ }\KeywordTok{nu_condit}\NormalTok{(nu_curr, theta_curr)}
\NormalTok{  pnu_new =}\StringTok{ }\KeywordTok{nu_condit}\NormalTok{(nu_new, theta_curr)}
\NormalTok{  accept =}\StringTok{ }\KeywordTok{exp}\NormalTok{(pnu_new }\OperatorTok{-}\StringTok{ }\NormalTok{pnu_curr)}
  \ControlFlowTok{if}\NormalTok{(}\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{<}\StringTok{ }\NormalTok{accept)}
\NormalTok{    nu_curr =}\StringTok{ }\NormalTok{nu_new}
  
\NormalTok{  sample}\OperatorTok{$}\NormalTok{theta[i] =}\StringTok{ }\NormalTok{theta_curr}
\NormalTok{  sample}\OperatorTok{$}\NormalTok{nu[i] =}\StringTok{ }\NormalTok{nu_new}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The effective sample size for \(\theta\) is

\begin{verbatim}
##     var1 
## 37.15345
\end{verbatim}

The effective sample size for \(\nu\) is

\begin{verbatim}
##     var1 
## 62.45584
\end{verbatim}

The table below summarizes the results

\begin{center}
\begin{tabular}{ |c|c|c| }
\hline
 parameter & mean & 95\% Credible Interval \\ 
 \hline
 $\theta$ & 1.13 & (0.635,1.846) \\  
 $\nu$ & 2.807 & (1.669, 4.55)\\
 \hline
\end{tabular}
\end{center}

The traceplots are below

\includegraphics{AMS206b_H4_files/figure-latex/unnamed-chunk-16-1.pdf}

The autocorrelation plots are below

\includegraphics{AMS206b_H4_files/figure-latex/unnamed-chunk-17-1.pdf}

\subsection{2B}\label{b-1}

Now we develop a Metropolis-Hastings algorithm that jointly proposes
\(\log(\nu)\) and \(\log(\theta)\) using a Gaussian random walk centered
on the current value of the parameters. Tune the variance-covariance
matrix of the proposal using a test run that proposes the parameters
independently:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{V =}\StringTok{ }\FloatTok{0.05}\OperatorTok{*}\KeywordTok{diag}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\NormalTok{theta_curr =}\StringTok{ }\DecValTok{2}
\NormalTok{nu_curr =}\StringTok{ }\DecValTok{3}
\NormalTok{N_test =}\StringTok{ }\DecValTok{5000}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{N_test)\{}
\NormalTok{  nu_new =}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\KeywordTok{log}\NormalTok{(nu_curr) }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\KeywordTok{sqrt}\NormalTok{(V[}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])))}
\NormalTok{  theta_new =}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\KeywordTok{log}\NormalTok{(theta_curr) }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{, V[}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{]))}
\NormalTok{  p_curr =}\StringTok{ }\KeywordTok{pcurr}\NormalTok{(nu_curr, theta_curr)}
\NormalTok{  p_new =}\StringTok{ }\KeywordTok{pcurr}\NormalTok{(nu_new, theta_new)}
\NormalTok{  accept =}\StringTok{ }\KeywordTok{exp}\NormalTok{(p_new }\OperatorTok{-}\StringTok{ }\NormalTok{p_curr)}
  \ControlFlowTok{if}\NormalTok{(}\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{<}\StringTok{ }\NormalTok{accept)\{}
\NormalTok{    nu_curr =}\StringTok{ }\NormalTok{nu_new}
\NormalTok{    theta_curr =}\StringTok{ }\NormalTok{theta_new}
\NormalTok{  \}}
\NormalTok{  sample}\OperatorTok{$}\NormalTok{theta[i] =}\StringTok{ }\NormalTok{theta_curr}
\NormalTok{  sample}\OperatorTok{$}\NormalTok{nu[i] =}\StringTok{ }\NormalTok{nu_curr}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in}\NormalTok{ N_test}\OperatorTok{+}\DecValTok{1}\OperatorTok{:}\DecValTok{10000}\NormalTok{)\{}
\NormalTok{  new =}\StringTok{ }\KeywordTok{mvrnorm}\NormalTok{(}\DecValTok{1}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\KeywordTok{log}\NormalTok{(nu_curr), }\KeywordTok{log}\NormalTok{(theta_curr)), V)}
\NormalTok{  nu_new =}\StringTok{ }\KeywordTok{exp}\NormalTok{(new[}\DecValTok{1}\NormalTok{])}
\NormalTok{  theta_new =}\StringTok{ }\KeywordTok{exp}\NormalTok{(new[}\DecValTok{2}\NormalTok{])}
\NormalTok{  p_curr =}\StringTok{ }\KeywordTok{pcurr2}\NormalTok{(nu_curr, theta_curr)}
\NormalTok{  p_new =}\StringTok{ }\KeywordTok{pcurr2}\NormalTok{(nu_new, theta_new)}
\NormalTok{  acceptance =}\StringTok{ }\KeywordTok{exp}\NormalTok{(p_new }\OperatorTok{-}\StringTok{ }\NormalTok{p_curr)}
  \ControlFlowTok{if}\NormalTok{(}\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{<}\StringTok{ }\NormalTok{acceptance)\{}
\NormalTok{    nu_curr =}\StringTok{ }\NormalTok{nu_new}
\NormalTok{    theta_curr =}\StringTok{ }\NormalTok{theta_new}
\NormalTok{  \}}
\NormalTok{  sample}\OperatorTok{$}\NormalTok{theta[i] =}\StringTok{ }\NormalTok{theta_curr}
\NormalTok{  sample}\OperatorTok{$}\NormalTok{nu[i] =}\StringTok{ }\NormalTok{nu_curr}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{center}
\begin{tabular}{ |c|c|c| }
\hline
 parameter & mean & 95\% Credible Interval \\ 
 \hline
 $\theta$ & 1.11 & (0.59,1.79) \\  
 $\nu$ & 2.807 & (1.49, 4.38)\\
 \hline
\end{tabular}
\end{center}

The trace plot for these samples are below

\includegraphics{AMS206b_H4_files/figure-latex/unnamed-chunk-21-1.pdf}

The corresponding autocorrelation plot is below

\includegraphics{AMS206b_H4_files/figure-latex/unnamed-chunk-22-1.pdf}

\subsection{2C}\label{c}

Now we are going to develop a Metropolis algorithm that jointly proposes
\(\log\nu\) and \(\log\theta\) using independent proposals based on
Laplace approximation of the posterior distribution of \(\log\nu\) and
\(\log\theta\).

We let \(t=\log\theta\) and \(v =\log\nu\), then the posterior becomes

\begin{align*} 
\pi(\theta,\nu|\pmb{x}) &\propto \exp\left\{(\nu -1) \sum_{i=1}^n \log x_i +(a -1)\log\nu - b\nu -n\log\Gamma(\nu) \right\}\\
&\times \exp\left\{(\alpha +n\nu-1)\log\theta -\theta\left(\beta + \sum_{i=1}^n x_i \right)\right\}\\
\Rightarrow \pi(t,v|\pmb{x}) &\propto \exp\left\{(e^v -1) sum_{i=1}^n \log x_i + av - be^v -n\log \Gamma(e^v)\right\}\\
&\times \exp\left\{(a +ne^v)t - e^t\left(\beta + sum_{i=1}^n x_i\right) \right\}
\end{align*}

Now, we let
\[h(t,v) = (e^v =1)\sum_{i=1}^n x_i + av -be^v-n\log \Gamma(e^v)\exp\left\{(a +ne^v)t - e^t\left(\beta + sum_{i=1}^n x_i\right) \right\}\]

Then we use the definition of Laplace approximation

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{h =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(w) \{}
\NormalTok{  a1 =}\StringTok{ }\NormalTok{(}\KeywordTok{exp}\NormalTok{(w[}\DecValTok{2}\NormalTok{]) }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{*}\StringTok{ }\NormalTok{sum_logx }\OperatorTok{+}\StringTok{ }\DecValTok{3} \OperatorTok{*}\StringTok{ }\NormalTok{w[}\DecValTok{2}\NormalTok{] }\OperatorTok{-}\StringTok{ }\KeywordTok{exp}\NormalTok{(w[}\DecValTok{2}\NormalTok{])}
  \KeywordTok{return}\NormalTok{(}\OperatorTok{-}\NormalTok{(a1 }\OperatorTok{-}\StringTok{ }\NormalTok{n }\OperatorTok{*}\StringTok{ }\KeywordTok{lgamma}\NormalTok{(}\KeywordTok{exp}\NormalTok{(w[}\DecValTok{2}\NormalTok{])) }\OperatorTok{+}\StringTok{ }
\StringTok{             }\NormalTok{(}\DecValTok{2} \OperatorTok{+}\StringTok{ }\NormalTok{n }\OperatorTok{*}\StringTok{ }\KeywordTok{exp}\NormalTok{(w[}\DecValTok{2}\NormalTok{])) }\OperatorTok{*}\StringTok{ }\NormalTok{w[}\DecValTok{1}\NormalTok{] }\OperatorTok{-}\StringTok{ }\KeywordTok{exp}\NormalTok{(w[}\DecValTok{1}\NormalTok{]) }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{2} \OperatorTok{+}\StringTok{ }\NormalTok{sum_x)))}
\NormalTok{\}}
\NormalTok{laplace =}\StringTok{ }\KeywordTok{optim}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), h, }\DataTypeTok{hessian =}\NormalTok{ T)}
\end{Highlighting}
\end{Shaded}

The laplace maximum for the parameters are

\begin{verbatim}
## [1] 0.09685737 1.00165219
\end{verbatim}

and the hessian obtained at the maximum is

\begin{verbatim}
##           [,1]      [,2]
## [1,]  70.06943 -68.06943
## [2,] -68.06943  85.06425
\end{verbatim}

Now we update the variance-covariance matrix then resume the Metropolis
sampling algorithm

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in}\NormalTok{ N_test}\OperatorTok{+}\DecValTok{1}\OperatorTok{:}\NormalTok{N)\{}
\NormalTok{  nu_new =}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\KeywordTok{log}\NormalTok{(nu_curr) }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\KeywordTok{sqrt}\NormalTok{(V[}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])))}
\NormalTok{  theta_new =}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\KeywordTok{log}\NormalTok{(theta_curr) }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\KeywordTok{sqrt}\NormalTok{(V[}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{])))}
\NormalTok{  p_curr =}\StringTok{ }\KeywordTok{pcurr}\NormalTok{(}\DataTypeTok{nu_curr =}\NormalTok{ nu_curr, }\DataTypeTok{theta_curr =}\NormalTok{ theta_curr)}
\NormalTok{  p_new =}\KeywordTok{pcurr}\NormalTok{(}\DataTypeTok{nu_curr =}\NormalTok{ nu_new, }\DataTypeTok{theta_curr =}\NormalTok{ theta_new)}
  
\NormalTok{  accept =}\StringTok{ }\KeywordTok{exp}\NormalTok{(p_new }\OperatorTok{-}\StringTok{ }\NormalTok{p_curr)}
  \ControlFlowTok{if}\NormalTok{(}\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{<}\StringTok{ }\NormalTok{accept)\{}
\NormalTok{    nu_curr =}\StringTok{ }\NormalTok{nu_new}
\NormalTok{    theta_curr =}\StringTok{ }\NormalTok{theta_new}
\NormalTok{  \}}
\NormalTok{  sample}\OperatorTok{$}\NormalTok{theta[i] =}\StringTok{ }\NormalTok{theta_curr}
\NormalTok{  sample}\OperatorTok{$}\NormalTok{nu[i] =}\StringTok{ }\NormalTok{nu_curr}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The corresponding traceplots are below

\includegraphics{AMS206b_H4_files/figure-latex/unnamed-chunk-27-1.pdf}

The corresponding autocorrelation plots are below

\includegraphics{AMS206b_H4_files/figure-latex/unnamed-chunk-28-1.pdf}

The effective sample size associated with \(\theta\) is

\begin{verbatim}
##     var1 
## 152.8612
\end{verbatim}

The effective sample size associated with \(\nu\) is

\begin{verbatim}
##     var1 
## 182.2601
\end{verbatim}

\begin{center}
\begin{tabular}{ |c|c|c| }
\hline
 parameter & mean & 95\% Credible Interval \\ 
 \hline
 $\theta$ & 1.05 & (0.56,1.58) \\  
 $\nu$ & 2.55 & (1.49, 3.79)\\
 \hline
\end{tabular}
\end{center}


\end{document}
